Pendulum-v1:
  policy: 'MlpPolicy'
  n_timesteps: 100000
  reward_threshold: -3.0

LunarLanderContinuous-v3:
  policy: 'MlpPolicy'
  n_timesteps: 100000
  reward_threshold: 195

Ant-v5:
  policy: 'MlpPolicy'
  n_timesteps: 100000
  reward_threshold: 1000

Humanoid-v5:
  policy: 'MlpPolicy'
  n_timesteps: 100000
  clip_range: 0.2
  n_steps: 32
  gamma: 0.95
  learning_rate: 2.1267809641089186e-05
  n_critic_updates: 20
  cg_max_steps: 20
  target_kl: 0.05
  gae_lambda: 1
  batch_size: 256
  net_arch: large
  activation_fn: tanh
  entropy_coef: 0.8300000000000001
  sampling_coef: 0.43999999999999995
  buffer_capacity: 10000
  epsilon: 0.4
  orthogonal_init: 1
  n_envs: 6
  normalize_advantage: 1

InvertedDoublePendulum-v5:
  policy: 'MlpPolicy'
  n_timesteps: 100000
  reward_threshold: 410

RocketLander-v0:
  policy: 'MlpPolicy'
  n_timesteps: 100000
  reward_threshold: -3.0

HalfCheetah-v5:
  policy: 'MlpPolicy'
  n_timesteps: 100000
  clip_range: 0.2
  n_steps: 8
  gamma: 0.99
  learning_rate: 0.0006419987179615489
  n_critic_updates: 30
  cg_max_steps: 20
  target_kl: 0.005
  gae_lambda: 0.8
  batch_size: 512
  activation_fn: relu
  entropy_coef: -0.31999999999999995
  sampling_coef: -0.6
  epsilon: 0.25
  orthogonal_init: 0
  n_envs: 6
  normalize_advantage: 0
  net_arch: large

Hopper-v5: 
  policy: 'MlpPolicy'
  n_timesteps: 100000

HumanoidStandup-v5:
  policy: 'MlpPolicy'
  n_timesteps: 100000

InvertedPendulum-v5:
  policy: 'MlpPolicy'
  n_timesteps: 100000

Pusher-v5:
  policy: 'MlpPolicy'
  n_timesteps: 100000

Reacher-v5:
  policy: 'MlpPolicy'
  n_timesteps: 100000

Swimmer-v5:
  policy: 'MlpPolicy'
  n_timesteps: 100000

Walker2d-v5:
  policy: 'MlpPolicy'
  n_timesteps: 100000

